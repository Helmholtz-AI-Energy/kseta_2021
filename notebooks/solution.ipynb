{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "internal-canberra",
   "metadata": {},
   "source": [
    "## KSETA Topical Courses\n",
    "### GPU Computing with PyTorch - High Performance Computing at KIT\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-thesis",
   "metadata": {},
   "source": [
    "#### Part 1 - Getting to Know PyTorch\n",
    "\n",
    "PyTorch is tensor computation library originally designed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "balanced-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0.dev20210208+cu110'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-rapid",
   "metadata": {},
   "source": [
    "Let us first create a vector from some user-defined data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decreased-dollar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1., -1.,  3.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([0.0, 1.0, -1.0, 3.0])\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-evanescence",
   "metadata": {},
   "source": [
    "It is also possible to initialize matrices, volumes and higher order tensors. Below you will find a two-dimensional, i.e. matrix, tensor example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "relative-appraisal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [6, 5, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [6, 5, 4]\n",
    "])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-colonial",
   "metadata": {},
   "source": [
    "PyTorch provides several functions to streamline tensor initialization. It is for example possible to create tensors with uninitialized memory, filled with constant values or random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "corporate-atlantic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9005, -0.2420, -0.0477,  0.0413, -2.5220],\n",
       "         [ 0.0699,  0.8276, -0.9583, -0.9358,  1.6107],\n",
       "         [ 0.0247,  0.5094, -0.7615,  0.4949, -0.4701],\n",
       "         [-0.1344,  0.6717, -0.7857,  1.6455,  2.6537]],\n",
       "\n",
       "        [[ 1.3203,  0.2742,  1.7353,  0.0259,  0.3806],\n",
       "         [-0.7005, -1.6252,  0.6543,  1.0404, -0.5003],\n",
       "         [ 0.5825,  1.4406, -0.5091,  0.7830,  0.5318],\n",
       "         [-1.4417, -0.4824,  1.3070, -1.5806, -0.5694]],\n",
       "\n",
       "        [[ 0.8968,  1.0666,  1.3685, -0.5930, -0.3702],\n",
       "         [-1.4366,  0.3959,  0.5588,  0.0815,  0.0174],\n",
       "         [ 0.2306, -0.4699, -0.0595, -0.3242,  0.1430],\n",
       "         [-0.8287,  1.0745,  1.6998, -1.1378,  0.8554]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_volume = torch.randn(size=(3, 4, 5))\n",
    "random_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-vault",
   "metadata": {},
   "source": [
    "Each PyTorch tensor has metadata associated with it that cannot only be queried, but also be modified in various calls. Some of the most commonly used metadata are a tensors `shape`, i.e. its dimensions, its `dtype`, i.e. the datatype of the elements, as well as the `device`, i.e. the processing device it is allocated on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dependent-bicycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 5]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_volume.shape, random_volume.dtype, random_volume.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "humanitarian-packet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.int64, device(type='cpu'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape, matrix.dtype, matrix.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-forty",
   "metadata": {},
   "source": [
    "The metadata values can also be manipulated, e.g. by changing the datatype or adjusting the shape. In the following code snippet, we change the dimensionality of a one-dimensional vector into a two dimensional matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "legitimate-trinity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.arange(10)\n",
    "vector.reshape(5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-slope",
   "metadata": {},
   "source": [
    "**Task 1:** try creating a tensor of data with the following dimensions `(100, 2, 2, 3)` and fill it with uniformly distributed `float64` values. Make use of PyTorch's `rand()` function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "creative-timothy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4779, 0.8963, 0.1564],\n",
       "          [0.9252, 0.2983, 0.8133]],\n",
       "\n",
       "         [[0.9342, 0.3185, 0.2259],\n",
       "          [0.6049, 0.2259, 0.5772]]],\n",
       "\n",
       "\n",
       "        [[[0.7891, 0.5376, 0.9887],\n",
       "          [0.6519, 0.1984, 0.2833]],\n",
       "\n",
       "         [[0.4949, 0.0753, 0.1490],\n",
       "          [0.7246, 0.2172, 0.8908]]],\n",
       "\n",
       "\n",
       "        [[[0.7072, 0.6258, 0.5013],\n",
       "          [0.9400, 0.8268, 0.3562]],\n",
       "\n",
       "         [[0.9671, 0.4080, 0.5342],\n",
       "          [0.4005, 0.1855, 0.6569]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.2861, 0.9914, 0.6111],\n",
       "          [0.4929, 0.2340, 0.2239]],\n",
       "\n",
       "         [[0.0257, 0.8508, 0.9453],\n",
       "          [0.6065, 0.9971, 0.4881]]],\n",
       "\n",
       "\n",
       "        [[[0.7435, 0.5496, 0.4005],\n",
       "          [0.6093, 0.0333, 0.7664]],\n",
       "\n",
       "         [[0.0948, 0.1662, 0.6652],\n",
       "          [0.7743, 0.4131, 0.3896]]],\n",
       "\n",
       "\n",
       "        [[[0.9662, 0.0760, 0.1183],\n",
       "          [0.6538, 0.1959, 0.5469]],\n",
       "\n",
       "         [[0.1809, 0.2175, 0.1672],\n",
       "          [0.1814, 0.4961, 0.9050]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(size=(100, 2, 2, 3), dtype=torch.float64)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-pennsylvania",
   "metadata": {},
   "source": [
    "----\n",
    "#### Part 2 - Operations and Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-owner",
   "metadata": {},
   "source": [
    "PyTorch supports several dozens of tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, and more. In the following examples we will have a brief look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "macro-armenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masses = torch.arange(10, dtype=torch.float32)\n",
    "masses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-booking",
   "metadata": {},
   "source": [
    "We can add two vectors of same length, resulting in a element-wise operation of the individual vector elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "official-heritage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(10,))\n",
    "masses + ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-poverty",
   "metadata": {},
   "source": [
    "**Slicing** allows us to index only parts of the data and continue working with it. The used indices are zero-based, left-inclusive and right-exclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "personalized-domain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masses[3:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-wheel",
   "metadata": {},
   "source": [
    "We can also formulate conditions, resulting in a boolean mask, which we can use to index data as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bizarre-variety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False, False, False, False, False, False, False, False,  True,  True]),\n",
       " tensor([8., 9.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masses > 7, masses[masses > 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-ordering",
   "metadata": {},
   "source": [
    "Vectors, matrices, volumes and so forth can also be combined with **scalars**. In this case the scalar in applied element-wise to each tensor element. Let us calculate Earth's gravitational force at ground-level for the previously defined masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "portable-annotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  9.8100, 19.6200, 29.4300, 39.2400, 49.0500, 58.8600, 68.6700,\n",
       "        78.4800, 88.2900])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gravitational_force = masses * 9.81\n",
    "gravitational_force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-order",
   "metadata": {},
   "source": [
    "PyTorch generally repeats operands if their shapes match, i.e. they have the same exact same dimension or the dimension is equal to one. This approach is called **broadcasting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wooden-centre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcast = torch.ones(size=(3, 10)) + masses\n",
    "broadcast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-heath",
   "metadata": {},
   "source": [
    "PyTorch also provides reduction operations that reduce entire tensors or subsets, e.g. columns or row, to singular values. Commonly used reduction operations are `min()`, `max()` or `sum()` for example. Let us have a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "connected-fashion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  6.,  9., 12., 15., 18., 21., 24., 27., 30.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcast.sum(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-chapel",
   "metadata": {},
   "source": [
    "Equally higher level operations are available like computing norms, matrix decompositions, or matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "progressive-heart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(285)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10) @ torch.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-soundtrack",
   "metadata": {},
   "source": [
    "**Task 2:** calculate mean and standard deviation along the first dimension for a normal-distributed data of dimensions `(100, 3)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ready-suite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.1332, -0.0706,  0.0398]), tensor([0.9320, 0.9582, 1.1153]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.randn(size=(100, 3))\n",
    "\n",
    "mean = (1.0 / data.shape[0]) * data.sum(dim=0)\n",
    "stddev = (1.0 / data.shape[0] * (data - mean) ** 2).sum(dim=0).sqrt()\n",
    "\n",
    "mean, stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-satin",
   "metadata": {},
   "source": [
    "----\n",
    "#### Part 3 - Using the GPU\n",
    "\n",
    "PyTorch enables you to leverage GPUs to accelerate computations. Particularly well suited-are numerical problems, e.g. linear algebra, with identical operations. Let us get to know PyTorch's `.cuda` submodule a little. First, we should make sure that PyTorch has been properly loaded and initialized the software, here: CUDA, to interact with GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "frank-florence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-festival",
   "metadata": {},
   "source": [
    "Everything seems to be in order. CUDA is available to PyTorch. Let us know check how many and what kind of GPUs we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "careful-deposit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'A100-SXM4-40GB')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count(), torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-czech",
   "metadata": {},
   "source": [
    "Let us now create a vector of data and move it from CPU to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "corporate-worse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.arange(10)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-mustang",
   "metadata": {},
   "source": [
    "Let us manually move the data to the GPU now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "introductory-failure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_gpu = m.cuda()\n",
    "m_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-immunology",
   "metadata": {},
   "source": [
    "Analogous to our previous usage of PyTorch, we can now GPU-accelerate computation by using the exact same interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "informal-potato",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_gpu.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-ceramic",
   "metadata": {},
   "source": [
    "PyTorch's library call that make it necessary that the data resides in the CPU's main memory, e.g. printing out values, move data automatically around. Yet, we can also do so manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "operational-remark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_gpu.cpu().device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-pasta",
   "metadata": {},
   "source": [
    "PyTorch offers several other ways of initializing data directly on the GPU. Below you will find the most common approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sensitive-support",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(2, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "modern-seattle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.FloatTensor([1.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "guided-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.randn(5).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-allah",
   "metadata": {},
   "source": [
    "Mixing devices is not possible and will result in an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "integrated-raising",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b2f282d322c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "torch.arange(10, device='cuda') + torch.arange(10, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-northeast",
   "metadata": {},
   "source": [
    "**Task 3:** we can now put all introduced elements together to make actual meaningful computations. For the following example, we load particle decays, simulated using the `phasespace` Python package, from disk and subsequently use PyTorch to compute the *thrust* for each event. The thrust is defined as:\n",
    "\n",
    "$$T=\\max\\limits_{\\vec{n}}\\frac{\\sum_j |\\vec{p}_j\\cdot\\vec{n}|}{\\sum_j |\\vec{p}_j|}$$\n",
    "\n",
    "Where $\\vec{p}_j$ are the particles' momenta and $\\vec{n}$ a vector with norm 1. The vector $\\vec{n}_T$ that maximizes the thrust is called the *thrust axis*. A thrust of $T\\approx\\frac{1}{2}$ implies a spherical momenta distribution, where as $T\\approx 1$ indicates strong jets.\n",
    "\n",
    "Let us download the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "sitting-procedure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000000, 6, 3]), device(type='cpu'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import util\n",
    "decays = util.download_data()\n",
    "decays.shape, decays.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-threat",
   "metadata": {},
   "source": [
    "In this example we have fifty million events, each consisting out of six final-state particles and their three x-, y- and z-momenta. According the formula above we will compute their thrust on the CPU first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cleared-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_thrust(events):\n",
    "    # simplified candidate estimation for n as average of particles\n",
    "    n = events.sum(dim=1)\n",
    "    # normalize n to be a unit vector\n",
    "    n_norms = torch.linalg.norm(n, dim=1, keepdim=True)\n",
    "    n /= n_norms\n",
    "    \n",
    "    # calculate both fraction components\n",
    "    nominator = torch.bmm(events, n.unsqueeze(dim=2)).sum(dim=(1, 2))\n",
    "    denominator = torch.linalg.norm(events, dim=2).sum(dim=1)\n",
    "    \n",
    "    # calculate thrust\n",
    "    thrust = nominator / denominator\n",
    "    \n",
    "    return thrust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "compact-being",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 28s, sys: 7.75 s, total: 8min 35s\n",
      "Wall time: 15.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8072), tensor(0.9632))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "thrust = compute_thrust(decays)\n",
    "thrust.min(), thrust.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "outdoor-australian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 325 ms, sys: 117 ms, total: 442 ms\n",
      "Wall time: 441 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8072, device='cuda:0'), tensor(0.9632, device='cuda:0'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "thrust = compute_thrust(decays.cuda())\n",
    "thrust.min(), thrust.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
